{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1708e5d6",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- A spatial model is definde in the following way:\n",
    "$$\n",
    "y_{it} = \\beta X_{it} + \\rho \\sum_{j=1}^{N} w_{it}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30998311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import bambi as bmb\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from src.data.data_reg import SpatialReg\n",
    "import matplotlib.pyplot as plt\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "\n",
    "\n",
    "num = 10\n",
    "rho = .8\n",
    "sr = SpatialReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = sr.spatial_simulation(time=10,rho=0.7, simulations=2, start_seed=787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97156c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d763df",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gdf = sr.spatial_df()\n",
    "n_obs = len(gdf)\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21914f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = sr.spatial_panel(rho=0.7, time=50, seed=787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79dca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49535c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf[\"time\"]==0].plot(\"y_true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a122937",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf[\"time\"]==1].plot(\"X_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dffe44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = gdf[[\"X_1\", \"X_2\", \"X_3\", \"w_rook\"]].values.reshape(-1,4)\n",
    "y_true = gdf[\"y_true\"].values.reshape(-1,1)\n",
    "X = sm.add_constant(xb)\n",
    "results = sm.OLS(y_true, X).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gdf.drop(\"geometry\", axis=1)\n",
    "y_true = df[\"y_true\"].values\n",
    "X_1 = df[\"X_1\"].values\n",
    "X_2 = df[\"X_2\"].values\n",
    "X_3 = df[\"X_3\"].values\n",
    "w = df[\"w_queen\"].values\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Define Priors\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=10)\n",
    "    intercept = pm.Normal(\"intercept\", 0, sigma=20)\n",
    "    beta_1 = pm.Normal(\"X_1\", 0, sigma=10)\n",
    "    beta_2 = pm.Normal(\"X_2\", 0, sigma=10)\n",
    "    beta_3 = pm.Normal(\"X_3\", 0, sigma=10)\n",
    "    rho = pm.Normal(\"rho\", 0, sigma=10)\n",
    "\n",
    "    # Define likelihood\n",
    "    likeligood = pm.Normal(\"y_true\", mu=intercept + beta_1 * X_1 + beta_2 * X_2 + beta_3 * X_3 + rho*w, sigma=sigma, observed=y_true)\n",
    "\n",
    "    idata = pm.sample(draws=3000, chains=10,cores=10)\n",
    "\n",
    "    posterior_predictive = pm.sample_posterior_predictive(idata).posterior_predictive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "posterior = az.extract(idata, num_samples=20)\n",
    "x_plot = xr.DataArray(np.linspace(1, 2, 100))\n",
    "y_plot = posterior[\"b\"] * x_plot + posterior[\"a\"]\n",
    "Line2 = ax.plot(x_plot, y_plot.transpose(), color=\"C1\")\n",
    "Line1 = ax.plot(x_pred, pred_mean, \"x\")\n",
    "ax.set(title=\"Posterior predictive regression lines\", xlabel=\"x\", ylabel=\"y\")\n",
    "ax.legend(\n",
    "    handles=[Line1[0], Line2[0]], labels=[\"predicted average\", \"inferred regression line\"], loc=0\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcaa5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239f7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4315b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we extract the posterior predictive samples\n",
    "posterior_predictive = pm.sample_posterior_predictive(idata, model=model)\n",
    "\n",
    "# The predicted values (y_pred) are stored in posterior_predictive['y_true']\n",
    "y_pred_samples = posterior_predictive.posterior_predictive['y_true'].values\n",
    "\n",
    "# Compute residuals for each posterior sample\n",
    "# Residuals = y_true - predicted values\n",
    "\n",
    "# Compute residuals for all posterior samples\n",
    "residuals = y_true - y_pred_samples\n",
    "\n",
    "# You can compute summary statistics of the residuals, such as mean and standard deviation\n",
    "mean_residuals = np.mean(residuals, axis=0)\n",
    "std_residuals = np.std(residuals, axis=0)\n",
    "\n",
    "print(\"Mean Residuals: \", mean_residuals)\n",
    "print(\"Standard Deviation of Residuals: \", std_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94bdfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_residuals.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "az_queen = az.summary(idata, hdi_prob=0.95)\n",
    "bayes_queen = az_queen[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f214225",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_knn6[\"X_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d62733",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata)\n",
    "az.summary(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80401e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gdf.drop(\"geometry\", axis=1)\n",
    "priors = {\n",
    "    \"w_queen\": bmb.Prior(\"Normal\", mu=0, sigma=2),\n",
    "}\n",
    "model = bmb.Model(\n",
    "    \"y_true ~ 1 + X_1 + X_2 + X_3 + w_queen\",\n",
    "    priors=priors,\n",
    "    data=df, \n",
    "    dropna=True\n",
    ")\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(results)\n",
    "az.summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44758b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "az_summary = az.summary(results, hdi_prob=0.95)\n",
    "az_summary[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"centroid\"] = gdf.centroid\n",
    "gdf[\"lat\"] = gdf[\"centroid\"].x\n",
    "gdf[\"lon\"] = gdf[\"centroid\"].y\n",
    "df = gdf.drop(\"geometry\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba2ba0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X = df[[\"X1\",\"lat\",\"lon\"]].values.reshape(-1,3)\n",
    "y = df[\"y_d\"].values.reshape(-1,1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8230d93",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Sort and extract variables\n",
    "gdf = gdf.sort_values([\"time\", \"id\"]).reset_index(drop=True)\n",
    "\n",
    "# Encode spatial unit ids as integers 0..N-1\n",
    "gdf[\"unit_id\"] = gdf[\"id\"].astype(\"category\").cat.codes\n",
    "N = gdf[\"unit_id\"].nunique()\n",
    "T = gdf[\"time\"].nunique()\n",
    "\n",
    "y = gdf[\"y_d\"].values\n",
    "X1 = gdf[\"X1\"].values\n",
    "Wy = gdf[\"w_d\"].values\n",
    "unit_idx = gdf[\"unit_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93912f09",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # Hyperpriors\n",
    "    sigma = pm.HalfNormal(\"sigma\", 2.0)\n",
    "    tau_rho = pm.HalfNormal(\"tau_rho\", 1.0)\n",
    "    tau_mu = pm.HalfNormal(\"tau_mu\", 1.0)\n",
    "\n",
    "    # Priors\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=5)\n",
    "    rho_i = pm.Normal(\"rho\", mu=0, sigma=tau_rho, shape=N)     # one rho per unit\n",
    "    mu_i = pm.Normal(\"mu\", mu=0, sigma=tau_mu, shape=N)         # one intercept per unit\n",
    "\n",
    "    # Create shared inputs\n",
    "    X_data = pm.Data(\"X1\", X1)\n",
    "    Wy_data = pm.Data(\"Wy\", Wy)\n",
    "    unit_idx_data = pm.Data(\"unit_idx\", unit_idx)\n",
    "\n",
    "    # Compute mu_y\n",
    "    mu_y = rho_i[unit_idx_data] * Wy_data + beta * X_data + mu_i[unit_idx_data]\n",
    "\n",
    "    # Likelihood\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=mu_y, sigma=sigma, observed=y)\n",
    "\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.9, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b64583",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# az.plot_trace(trace, var_names=[\"rho\", \"beta\", \"sigma\"])\n",
    "# az.summary(trace, var_names=[\"rho\", \"beta\", \"sigma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c461a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_true = .8\n",
    "summary = az.summary(trace, var_names=[\"rho\"], hdi_prob=0.94)\n",
    "within_hdi = (rho_true >= summary[\"hdi_3%\"]) & (rho_true <= summary[\"hdi_97%\"])\n",
    "\n",
    "# Report results\n",
    "all_contain = within_hdi.all()\n",
    "num_pass = within_hdi.sum()\n",
    "num_total = len(within_hdi)\n",
    "\n",
    "print(f\"True rho = {rho_true}\")\n",
    "print(f\"{num_pass}/{num_total} HDIs contain true rho.\")\n",
    "\n",
    "# Optionally, list which units failed\n",
    "if not all_contain:\n",
    "    failed_units = np.where(~within_hdi)[0]\n",
    "    print(f\"Units failing HDI test: {failed_units}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
