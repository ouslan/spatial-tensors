{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30998311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spreg\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import bambi as bmb\n",
    "from pysal.lib import weights\n",
    "import polars as pl\n",
    "\n",
    "from src.data.data_reg import SpatialReg\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "\n",
    "sr = SpatialReg(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21914f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = sr.spatial_panel(n=10,time=5,rho=.8)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49535c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf[\"time\"]==0].plot(\"X1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a122937",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf[\"time\"]==0].plot(\"y_d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12656b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = weights.contiguity.Rook.from_dataframe(gdf[gdf[\"time\"] == 0])\n",
    "wr.transform = \"r\"\n",
    "y_d = gdf[\"y_d\"].values.reshape(-1,1)\n",
    "xb = gdf[\"X1\"].values.reshape(-1,1)\n",
    "fe_lag = spreg.Panel_FE_Lag(y=y_d, x=xb, w=wr)\n",
    "print(fe_lag.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80401e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gdf.drop(\"geometry\", axis=1)\n",
    "model = bmb.Model(\n",
    "    \"y_d ~ 1 + X1 + (0 + w_d|id)\",\n",
    "    df, dropna=True\n",
    ")\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"centroid\"] = gdf.centroid\n",
    "gdf[\"lat\"] = gdf[\"centroid\"].x\n",
    "gdf[\"lon\"] = gdf[\"centroid\"].y\n",
    "df = gdf.drop(\"geometry\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"X1\",\"lat\",\"lon\"]].values.reshape(-1,3)\n",
    "y = df[\"y_d\"].values.reshape(-1,1)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8230d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and extract variables\n",
    "gdf = gdf.sort_values([\"time\", \"id\"]).reset_index(drop=True)\n",
    "\n",
    "# Encode spatial unit ids as integers 0..N-1\n",
    "gdf[\"unit_id\"] = gdf[\"id\"].astype(\"category\").cat.codes\n",
    "N = gdf[\"unit_id\"].nunique()\n",
    "T = gdf[\"time\"].nunique()\n",
    "\n",
    "y = gdf[\"y_d\"].values\n",
    "X1 = gdf[\"X1\"].values\n",
    "Wy = gdf[\"w_d\"].values\n",
    "unit_idx = gdf[\"unit_id\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93912f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # Hyperpriors\n",
    "    sigma = pm.HalfNormal(\"sigma\", 1.0)\n",
    "    tau_rho = pm.HalfNormal(\"tau_rho\", 1.0)\n",
    "    tau_mu = pm.HalfNormal(\"tau_mu\", 1.0)\n",
    "\n",
    "    # Priors\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=5)\n",
    "    rho_i = pm.Normal(\"rho\", mu=0, sigma=tau_rho, shape=N)     # one rho per unit\n",
    "    mu_i = pm.Normal(\"mu\", mu=0, sigma=tau_mu, shape=N)         # one intercept per unit\n",
    "\n",
    "    # Create shared inputs\n",
    "    X_data = pm.Data(\"X1\", X1)\n",
    "    Wy_data = pm.Data(\"Wy\", Wy)\n",
    "    unit_idx_data = pm.Data(\"unit_idx\", unit_idx)\n",
    "\n",
    "    # Compute mu_y\n",
    "    mu_y = rho_i[unit_idx_data] * Wy_data + beta * X_data + mu_i[unit_idx_data]\n",
    "\n",
    "    # Likelihood\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=mu_y, sigma=sigma, observed=y)\n",
    "\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.9, return_inferencedata=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b64583",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace, var_names=[\"rho\", \"beta\", \"sigma\"])\n",
    "az.summary(trace, var_names=[\"rho\", \"beta\", \"sigma\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c461a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_true = .8\n",
    "summary = az.summary(trace, var_names=[\"rho\"], hdi_prob=0.94)\n",
    "within_hdi = (rho_true >= summary[\"hdi_3%\"]) & (rho_true <= summary[\"hdi_97%\"])\n",
    "\n",
    "# Report results\n",
    "all_contain = within_hdi.all()\n",
    "num_pass = within_hdi.sum()\n",
    "num_total = len(within_hdi)\n",
    "\n",
    "print(f\"True rho = {rho_true}\")\n",
    "print(f\"{num_pass}/{num_total} HDIs contain true rho.\")\n",
    "print(\"All HDIs contain true rho.\" if all_contain else \"Not all HDIs contain true rho.\")\n",
    "\n",
    "# Optionally, list which units failed\n",
    "if not all_contain:\n",
    "    failed_units = np.where(~within_hdi)[0]\n",
    "    print(f\"Units failing HDI test: {failed_units}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
